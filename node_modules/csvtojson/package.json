{
  "_from": "csvtojson",
  "_id": "csvtojson@2.0.10",
  "_inBundle": false,
  "_integrity": "sha512-lUWFxGKyhraKCW8Qghz6Z0f2l/PqB1W3AO0HKJzGIQ5JRSlR651ekJDiGJbBT4sRNNv5ddnSGVEnsxP9XRCVpQ==",
  "_location": "/csvtojson",
  "_phantomChildren": {},
  "_requested": {
    "escapedName": "csvtojson",
    "fetchSpec": "latest",
    "name": "csvtojson",
    "raw": "csvtojson",
    "rawSpec": "",
    "registry": true,
    "saveSpec": null,
    "type": "tag"
  },
  "_requiredBy": [
    "#USER",
    "/"
  ],
  "_resolved": "https://registry.npmjs.org/csvtojson/-/csvtojson-2.0.10.tgz",
  "_shasum": "11e7242cc630da54efce7958a45f443210357574",
  "_spec": "csvtojson",
  "_where": "F:\\Project\\Project-X",
  "author": {
    "email": "keyang.xiang@gmail.com",
    "name": "Keyang Xiang"
  },
  "bin": {
    "csvtojson": "./bin/csvtojson"
  },
  "browser": "./browser/browser.js",
  "bugs": {
    "url": "https://github.com/Keyang/node-csvtojson/issues"
  },
  "bundleDependencies": false,
  "contributors": [
    {
      "name": "Hocine Moukaideche",
      "url": "https://github.com/Off76"
    },
    {
      "name": "Dane Petersen",
      "url": "https://github.com/thegreatsunra"
    },
    {
      "url": "https://github.com/nbelakovski"
    },
    {
      "name": "Robert Porter",
      "url": "https://github.com/colarob"
    },
    {
      "name": "Dimitri Kennedy",
      "url": "https://github.com/roodboi"
    },
    {
      "name": "José Expósito",
      "url": "https://github.com/JoseExposito"
    },
    {
      "name": "Daniel Cohen",
      "url": "https://github.com/dcohenb"
    },
    {
      "name": "Richard Pringle",
      "url": "https://github.com/richardpringle"
    },
    {
      "name": "Bert Verhelst",
      "url": "https://github.com/bertyhell"
    },
    {
      "url": "https://github.com/jondayft"
    },
    {
      "name": "Bruce Johnson",
      "url": "https://github.com/brucejo75"
    },
    {
      "name": "Jimi Ford",
      "url": "https://github.com/JimiHFord"
    },
    {
      "name": "Alec Fenichel",
      "url": "https://github.com/fenichelar"
    },
    {
      "name": "Jessica Good",
      "url": "https://github.com/jessicagood"
    },
    {
      "name": "Blake Blackshear",
      "url": "https://github.com/blakeblackshear"
    },
    {
      "name": "Amila Welihinda",
      "url": "https://github.com/amilajack"
    },
    {
      "name": "Zsolt R. Molnar",
      "url": "https://github.com/molnarzs"
    },
    {
      "name": "Ionică Bizău",
      "url": "Johnny B."
    },
    {
      "name": "Keita Akutsu",
      "url": "https://github.com/kakts"
    },
    {
      "url": "https://github.com/markwithers"
    },
    {
      "name": "Trang",
      "url": "https://github.com/trangtungn"
    },
    {
      "name": "Keyang Xiang",
      "url": "https://github.com/Keyang"
    },
    {
      "name": "Jeff Johnson",
      "url": "https://github.com/jeffcjohnson"
    },
    {
      "name": "Sean Lang",
      "url": "https://github.com/slang800"
    },
    {
      "name": "Matthias Lienau",
      "url": "https://github.com/atufkas"
    },
    {
      "name": "Ron Korving",
      "url": "https://github.com/ronkorving"
    }
  ],
  "dependencies": {
    "bluebird": "^3.5.1",
    "lodash": "^4.17.3",
    "strip-bom": "^2.0.0"
  },
  "deprecated": false,
  "description": "A tool concentrating on converting csv data to JSON with customised parser supporting",
  "devDependencies": {
    "@types/bluebird": "^3.5.20",
    "@types/mocha": "^5.2.0",
    "@types/node": "^10.0.1",
    "babel-plugin-syntax-dynamic-import": "^6.18.0",
    "coveralls": "^3.0.1",
    "minimist": "^1.2.0",
    "mocha": "^5.1.1",
    "nyc": "^11.7.3",
    "sinon": "^3.2.3",
    "ts-node": "^6.0.3",
    "typescript": "^2.8.3",
    "uglifyjs-webpack-plugin": "^1.2.7",
    "webpack": "^4.16.4",
    "webpack-cli": "^3.1.0"
  },
  "engines": {
    "node": ">=4.0.0"
  },
  "homepage": "https://github.com/Keyang/node-csvtojson",
  "keywords": [
    "convert csv to json",
    "csv",
    "csv convert",
    "csv parser",
    "csv to json",
    "csv-json",
    "csvtojson",
    "json",
    "parse csv",
    "tojson"
  ],
  "license": "MIT",
  "main": "./v2/index.js",
  "name": "csvtojson",
  "nyc": {
    "all": true,
    "extension": [
      ".ts",
      ".tsx"
    ],
    "include": [
      "./src/**/*.ts"
    ]
  },
  "optionalDependencies": {},
  "readme": "[![Build Status](https://travis-ci.org/Keyang/node-csvtojson.svg?branch=master)](https://travis-ci.org/Keyang/node-csvtojson)\n[![Coverage Status](https://coveralls.io/repos/github/Keyang/node-csvtojson/badge.svg?branch=master)](https://coveralls.io/github/Keyang/node-csvtojson?branch=master)\n[![OpenCollective](https://opencollective.com/csvtojson/backers/badge.svg)](#backers) \n[![OpenCollective](https://opencollective.com/csvtojson/sponsors/badge.svg)](#sponsors)\n\n# CSVTOJSON\n\n`csvtojson` module is a comprehensive nodejs csv parser to convert csv to json or column arrays. It can be used as node.js library / command line tool / or in browser. Below are some features:\n\n*  Strictly follow CSV definition [RF4180](https://www.loc.gov/preservation/digital/formats/fdd/fdd000323.shtml)\n*  Work with millions of lines of CSV data\n*  Provide comprehensive parsing parameters\n*  Provide out of box CSV parsing tool for Command Line\n*  Blazing fast -- [Focus on performance](https://github.com/Keyang/csvbench)\n*  Give flexibility to developer with 'pre-defined' helpers\n*  Allow async / streaming parsing\n*  Provide a csv parser for both Node.JS and browsers\n*  Easy to use API\n\n\n# csvtojson online \n\n[Here](http://keyangxiang.com/csvtojson/) is a free online csv to json convert service utilizing latest `csvtojson` module.\n\n# Upgrade to V2\n\n`csvtojson` has released version `2.0.0`. \n* To upgrade to v2, please follow [upgrading guide](https://github.com/Keyang/node-csvtojson/blob/master/docs/csvtojson-v2.md)\n* If you are looking for documentation for `v1`, open [this page](https://github.com/Keyang/node-csvtojson/blob/master/docs/readme.v1.md)\n\nIt is still able to use v1 with `csvtojson@2.0.0`\n\n```js\n// v1\nconst csvtojsonV1=require(\"csvtojson/v1\");\n// v2\nconst csvtojsonV2=require(\"csvtojson\");\nconst csvtojsonV2=require(\"csvtojson/v2\");\n\n```\n\n# Menu\n\n* [Quick Start](#quick-start)\n* [API](#api)\n* [Browser Usage](#browser-usage)\n* [Contribution](#contribution)\n\n# Quick Start\n\n* [As Library](#library)\n* [As Command Line Tool](#command-line-usage)\n\n## Library\n\n### Installation\n\n```\nnpm i --save csvtojson\n```\n\n### From CSV File to JSON Array\n\n```js\n/** csv file\na,b,c\n1,2,3\n4,5,6\n*/\nconst csvFilePath='<path to csv file>'\nconst csv=require('csvtojson')\ncsv()\n.fromFile(csvFilePath)\n.then((jsonObj)=>{\n\tconsole.log(jsonObj);\n\t/**\n\t * [\n\t * \t{a:\"1\", b:\"2\", c:\"3\"},\n\t * \t{a:\"4\", b:\"5\". c:\"6\"}\n\t * ]\n\t */ \n})\n\n// Async / await usage\nconst jsonArray=await csv().fromFile(csvFilePath);\n\n```\n\n### From CSV String to CSV Row\n\n```js\n/**\ncsvStr:\n1,2,3\n4,5,6\n7,8,9\n*/\nconst csv=require('csvtojson')\ncsv({\n\tnoheader:true,\n\toutput: \"csv\"\n})\n.fromString(csvStr)\n.then((csvRow)=>{ \n\tconsole.log(csvRow) // => [[\"1\",\"2\",\"3\"], [\"4\",\"5\",\"6\"], [\"7\",\"8\",\"9\"]]\n})\n\n```\n\n\n### Asynchronously process each line from csv url\n\n```js\nconst request=require('request')\nconst csv=require('csvtojson')\n\ncsv()\n.fromStream(request.get('http://mywebsite.com/mycsvfile.csv'))\n.subscribe((json)=>{\n\treturn new Promise((resolve,reject)=>{\n\t\t// long operation for each json e.g. transform / write into database.\n\t})\n},onError,onComplete);\n\n```\n\n### Convert to CSV lines\n\n```js\n/**\ncsvStr:\na,b,c\n1,2,3\n4,5,6\n*/\n\nconst csv=require('csvtojson')\ncsv({output:\"line\"})\n.fromString(csvStr)\n.subscribe((csvLine)=>{ \n\t// csvLine =>  \"1,2,3\" and \"4,5,6\"\n})\n```\n\n### Use Stream\n\n```js\nconst csv=require('csvtojson');\n\nconst readStream=require('fs').createReadStream(csvFilePath);\n\nconst writeStream=request.put('http://mysite.com/obj.json');\n\nreadStream.pipe(csv()).pipe(writeStream);\n\n```\n\nTo find more detailed usage, please see [API](#api) section\n\n## Command Line Usage\n\n### Installation\n\n```\n$ npm i -g csvtojson\n```\n\n### Usage\n\n\n```\n$ csvtojson [options] <csv file path>\n```\n\n### Example\n\nConvert csv file and save result to json file:\n\n```\n$ csvtojson source.csv > converted.json\n```\n\nPipe in csv data:\n\n```\n$ cat ./source.csv | csvtojson > converted.json\n```\n\nPrint Help:\n\n```\n$ csvtojson\n```\n\n# API\n\n* [Parameters](#parameters)\n* [Asynchronous Result Process](#asynchronous-result-process)\n* [Events](#events)\n* [Hook / Transform](#hook--transform)\n* [Nested JSON Structure](#nested-json-structure)\n* [Header Row](#header-row)\n* [Column Parser](#column-parser)\n\n\n## Parameters\n\n`require('csvtojson')` returns a constructor function which takes 2 arguments:\n\n1. Parser parameters\n2. Stream options\n\n```js\nconst csv=require('csvtojson')\nconst converter=csv(parserParameters, streamOptions)\n```\nBoth arguments are optional.\n\nFor `Stream Options` please read [Stream Option](https://nodejs.org/api/stream.html#stream_new_stream_transform_options) from Node.JS\n\n`parserParameters` is a JSON object like:\n\n```js\nconst converter=csv({\n\tnoheader:true,\n\ttrim:true,\n})\n```\nFollowing parameters are supported:\n\n* **output**: The format to be converted to. \"json\" (default) -- convert csv to json. \"csv\" -- convert csv to csv row array. \"line\" -- convert csv to csv line string  \n* **delimiter**: delimiter used for separating columns. Use \"auto\" if delimiter is unknown in advance, in this case, delimiter will be auto-detected (by best attempt). Use an array to give a list of potential delimiters e.g. [\",\",\"|\",\"$\"]. default: \",\"\n* **quote**: If a column contains delimiter, it is able to use quote character to surround the column content. e.g. \"hello, world\" won't be split into two columns while parsing. Set to \"off\" will ignore all quotes. default: \" (double quote)\n* **trim**: Indicate if parser trim off spaces surrounding column content. e.g. \"  content  \" will be trimmed to \"content\". Default: true\n* **checkType**: This parameter turns on and off whether check field type. Default is false. (The default is `true` if version < 1.1.4)\n* **ignoreEmpty**: Ignore the empty value in CSV columns. If a column value is not given, set this to true to skip them. Default: false.\n* **fork (experimental)**: Fork another process to parse the CSV stream. It is effective if many concurrent parsing sessions for large csv files. Default: false\n* **noheader**:Indicating csv data has no header row and first row is data row. Default is false. See [header row](#header-row)\n* **headers**: An array to specify the headers of CSV data. If --noheader is false, this value will override CSV header row. Default: null. Example: [\"my field\",\"name\"]. See [header row](#header-row)\n* **flatKeys**: Don't interpret dots (.) and square brackets in header fields as nested object or array identifiers at all (treat them like regular characters for JSON field identifiers). Default: false.\n* **maxRowLength**: the max character a csv row could have. 0 means infinite. If max number exceeded, parser will emit \"error\" of \"row_exceed\". if a possibly corrupted csv data provided, give it a number like 65535 so the parser won't consume memory. default: 0\n* **checkColumn**: whether check column number of a row is the same as headers. If column number mismatched headers number, an error of \"mismatched_column\" will be emitted.. default: false\n* **eol**: End of line character. If omitted, parser will attempt to retrieve it from the first chunks of CSV data.\n* **escape**: escape character used in quoted column. Default is double quote (\") according to RFC4108. Change to back slash (\\\\) or other chars for your own case.\n* **includeColumns**: This parameter instructs the parser to include only those columns as specified by the regular expression. Example: /(name|age)/ will parse and include columns whose header contains \"name\" or \"age\"\n* **ignoreColumns**: This parameter instructs the parser to ignore columns as specified by the regular expression. Example: /(name|age)/ will ignore columns whose header contains \"name\" or \"age\"\n* **colParser**: Allows override parsing logic for a specific column. It accepts a JSON object with fields like: `headName: <String | Function | ColParser>` . e.g. {field1:'number'} will use built-in number parser to convert value of the `field1` column to number. For more information See [details below](#column-parser)\n* **alwaysSplitAtEOL**: Always interpret each line (as defined by `eol` like `\\n`) as a row. This will prevent `eol` characters from being used within a row (even inside a quoted field). Default is false. Change to true if you are confident no inline line breaks (like line break in a cell which has multi line text).\n* **nullObject**: How to parse if a csv cell contains \"null\". Default false will keep \"null\" as string. Change to true if a null object is needed.\n* **downstreamFormat**: Option to set what JSON array format is needed by downstream. \"line\" is also called ndjson format. This format will write lines of JSON (without square brackets and commas) to downstream. \"array\" will write complete JSON array string to downstream (suitable for file writable stream etc). Default \"line\"\n* **needEmitAll**: Parser will build JSON result is `.then` is called (or await is used). If this is not desired, set this to false. Default is true. \nAll parameters can be used in Command Line tool.\n\n## Asynchronous Result Process\n\nSince `v2.0.0`, asynchronous processing has been fully supported.\n\ne.g. Process each JSON result asynchronously.\n\n```js\ncsv().fromFile(csvFile)\n.subscribe((json)=>{\n\treturn new Promise((resolve,reject)=>{\n\t\t// Async operation on the json\n\t\t// don't forget to call resolve and reject\n\t})\n})\n```\nFor more details please read:\n\n* [Add Promise and Async / Await support](https://github.com/Keyang/node-csvtojson/blob/master/docs/csvtojson-v2.md#add-promise-and-async--await-support)\n* [Add asynchronous line by line processing support](https://github.com/Keyang/node-csvtojson/blob/master/docs/csvtojson-v2.md#add-asynchronous-line-by-line-processing-support)\n* [Async Hooks Support](https://github.com/Keyang/node-csvtojson/blob/master/docs/csvtojson-v2.md#async-hooks-support)\n\n\n## Events\n\n`Converter` class defined a series of events.\n\n### header\n\n`header` event is emitted for each CSV file once. It passes an array object which contains the names of the header row.\n\n```js\nconst csv=require('csvtojson')\ncsv()\n.on('header',(header)=>{\n\t//header=> [header1, header2, header3]\n})\n```\n\n`header` is always an array of strings without types.\n\n### data\n\n`data` event is emitted for each parsed CSV line. It passes buffer of stringified JSON in [ndjson format](http://ndjson.org/) unless `objectMode` is set true in stream option.\n\n```js\nconst csv=require('csvtojson')\ncsv()\n.on('data',(data)=>{\n\t//data is a buffer object\n\tconst jsonStr= data.toString('utf8')\n})\n```\n\n### error\n`error` event is emitted if any errors happened during parsing.\n\n```js\nconst csv=require('csvtojson')\ncsv()\n.on('error',(err)=>{\n\tconsole.log(err)\n})\n```\n\nNote that if `error` being emitted, the process will stop as node.js will automatically `unpipe()` upper-stream and chained down-stream<sup>1</sup>. This will cause `end` event never being emitted because `end` event is only emitted when all data being consumed <sup>2</sup>. If need to know when parsing finished, use `done` event instead of `end`.\n\n1. [Node.JS Readable Stream](https://github.com/nodejs/node/blob/master/lib/_stream_readable.js#L572-L583)\n2. [Writable end Event](https://nodejs.org/api/stream.html#stream_event_end)\n\n### done\n\n`done` event is emitted either after parsing successfully finished or any error happens. This indicates the processor has stopped.\n\n```js\nconst csv=require('csvtojson')\ncsv()\n.on('done',(error)=>{\n\t//do some stuff\n})\n```\n\nif any error during parsing, it will be passed in callback.\n\n## Hook & Transform\n\n### Raw CSV Data Hook\n\nthe hook -- `preRawData` will be called with csv string passed to parser.\n\n```js\nconst csv=require('csvtojson')\n// synchronouse\ncsv()\n.preRawData((csvRawData)=>{\n\tvar newData=csvRawData.replace('some value','another value');\n\treturn newData;\n})\n\n// asynchronous\ncsv()\n.preRawData((csvRawData)=>{\n\treturn new Promise((resolve,reject)=>{\n\t\tvar newData=csvRawData.replace('some value','another value');\n\t\tresolve(newData);\n\t})\n\t\n})\n```\n\n### CSV File Line Hook\n\nThe function is called each time a file line has been parsed in csv stream. The `lineIdx` is the file line number in the file starting with 0. \n\n```js\nconst csv=require('csvtojson')\n// synchronouse\ncsv()\n.preFileLine((fileLineString, lineIdx)=>{\n\tif (lineIdx === 2){\n\t\treturn fileLineString.replace('some value','another value')\n\t}\n\treturn fileLineString\n})\n\n// asynchronous\ncsv()\n.preFileLine((fileLineString, lineIdx)=>{\n\treturn new Promise((resolve,reject)=>{\n\t\t\t// async function processing the data.\n\t})\n\t\n\t\n})\n```\n\n\n\n### Result transform\n\nTo transform result that is sent to downstream, use `.subscribe` method for each json populated.\n\n```js\nconst csv=require('csvtojson')\ncsv()\n.subscribe((jsonObj,index)=>{\n\tjsonObj.myNewKey='some value'\n\t// OR asynchronously\n\treturn new Promise((resolve,reject)=>{\n\t\tjsonObj.myNewKey='some value';\n\t\tresolve();\n\t})\n})\n.on('data',(jsonObj)=>{\n\tconsole.log(jsonObj.myNewKey) // some value\n});\n```\n\n\n## Nested JSON Structure\n\n`csvtojson` is able to convert csv line to a nested JSON by correctly defining its csv header row. This is default out-of-box feature.\n\nHere is an example. Original CSV:\n\n```csv\nfieldA.title, fieldA.children.0.name, fieldA.children.0.id,fieldA.children.1.name, fieldA.children.1.employee.0.name,fieldA.children.1.employee.1.name, fieldA.address.0,fieldA.address.1, description\nFood Factory, Oscar, 0023, Tikka, Tim, Joe, 3 Lame Road, Grantstown, A fresh new food factory\nKindom Garden, Ceil, 54, Pillow, Amst, Tom, 24 Shaker Street, HelloTown, Awesome castle\n\n```\nThe data above contains nested JSON including nested array of JSON objects and plain texts.\n\nUsing csvtojson to convert, the result would be like:\n\n```json\n[{\n    \"fieldA\": {\n        \"title\": \"Food Factory\",\n        \"children\": [{\n            \"name\": \"Oscar\",\n            \"id\": \"0023\"\n        }, {\n            \"name\": \"Tikka\",\n            \"employee\": [{\n                \"name\": \"Tim\"\n            }, {\n                \"name\": \"Joe\"\n            }]\n        }],\n        \"address\": [\"3 Lame Road\", \"Grantstown\"]\n    },\n    \"description\": \"A fresh new food factory\"\n}, {\n    \"fieldA\": {\n        \"title\": \"Kindom Garden\",\n        \"children\": [{\n            \"name\": \"Ceil\",\n            \"id\": \"54\"\n        }, {\n            \"name\": \"Pillow\",\n            \"employee\": [{\n                \"name\": \"Amst\"\n            }, {\n                \"name\": \"Tom\"\n            }]\n        }],\n        \"address\": [\"24 Shaker Street\", \"HelloTown\"]\n    },\n    \"description\": \"Awesome castle\"\n}]\n```\n\n### Flat Keys\n\nIn order to not produce nested JSON, simply set `flatKeys:true` in parameters.\n\n```js\n/**\ncsvStr:\na.b,a.c\n1,2\n*/\ncsv({flatKeys:true})\n.fromString(csvStr)\n.subscribe((jsonObj)=>{\n\t//{\"a.b\":1,\"a.c\":2}  rather than  {\"a\":{\"b\":1,\"c\":2}}\n});\n\n```\n\n## Header Row\n\n`csvtojson` uses csv header row as generator of JSON keys. However, it does not require the csv source containing a header row. There are 4 ways to define header rows:\n\n1. First row of csv source. Use first row of csv source as header row. This is default.\n2. If first row of csv source is header row but it is incorrect and need to be replaced. Use `headers:[]` and `noheader:false` parameters.\n3. If original csv source has no header row but the header definition can be defined. Use `headers:[]` and `noheader:true` parameters.\n4. If original csv source has no header row and the header definition is unknown. Use `noheader:true`. This will automatically add `fieldN` header to csv cells\n\n\n### Example\n\n```js\n// replace header row (first row) from original source with 'header1, header2'\ncsv({\n\tnoheader: false,\n\theaders: ['header1','header2']\n})\n\n// original source has no header row. add 'field1' 'field2' ... 'fieldN' as csv header\ncsv({\n\tnoheader: true\n})\n\n// original source has no header row. use 'header1' 'header2' as its header row\ncsv({\n\tnoheader: true,\n\theaders: ['header1','header2']\n})\n\n```\n\n## Column Parser\n\n`Column Parser` allows writing a custom parser for a column in CSV data. \n\n**What is Column Parser**\n\nWhen `csvtojson` walks through csv data, it converts value in a cell to something else. For example, if `checkType` is `true`, `csvtojson` will attempt to find a proper type parser according to the cell value. That is, if cell value is \"5\", a `numberParser` will be used and all value under that column will use the `numberParser` to transform data.\n\n### Built-in parsers\n\nThere are currently following built-in parser:\n\n* string: Convert value to string\n* number: Convert value to number\n* omit: omit the whole column\n\nThis will override types infered from `checkType:true` parameter. More built-in parsers will be added as requested in [issues page](https://github.com/Keyang/node-csvtojson/issues).\n\nExample:\n\n```js\n/*csv string\ncolumn1,column2\nhello,1234\n*/\ncsv({\n\tcolParser:{\n\t\t\"column1\":\"omit\",\n\t\t\"column2\":\"string\",\n\t},\n\tcheckType:true\n})\n.fromString(csvString)\n.subscribe((jsonObj)=>{\n\t//jsonObj: {column2:\"1234\"}\n})\n```\n\n### Custom parsers function\n\nSometimes, developers want to define custom parser. It is able to pass a function to specific column in `colParser`.\n\nExample:\n\n```js\n/*csv data\nname, birthday\nJoe, 1970-01-01\n*/\ncsv({\n\tcolParser:{\n\t\t\"birthday\":function(item, head, resultRow, row , colIdx){\n\t\t\t/*\n\t\t\t\titem - \"1970-01-01\"\n\t\t\t\thead - \"birthday\"\n\t\t\t\tresultRow - {name:\"Joe\"}\n\t\t\t\trow - [\"Joe\",\"1970-01-01\"]\n\t\t\t\tcolIdx - 1\n\t\t\t*/\n\t\t\treturn new Date(item);\n\t\t}\n\t}\n})\n```\n\nAbove example will convert `birthday` column into a js `Date` object.\n\nThe returned value will be used in result JSON object. Returning `undefined` will not change result JSON object. \n\n### Flat key column\n\nIt is also able to mark a column as `flat`:\n\n```js\n\n/*csv string\nperson.comment,person.number\nhello,1234\n*/\ncsv({\n\tcolParser:{\n\t\t\"person.number\":{\n\t\t\tflat:true,\n\t\t\tcellParser: \"number\" // string or a function \n\t\t}\n\t}\n})\n.fromString(csvString)\n.subscribe((jsonObj)=>{\n\t//jsonObj: {\"person.number\":1234,\"person\":{\"comment\":\"hello\"}}\n})\n```\n\n# Contribution\n\nVery much appreciate any types of donation and support. \n\n## Code\n\n`csvtojson` follows github convention for contributions. Here are some steps:\n\n1. Fork the repo to your github account\n2. Checkout code from your github repo to your local machine.\n3. Make code changes and don't forget add related tests.\n4. Run `npm test` locally before pushing code back.\n5. Create a [Pull Request](https://help.github.com/articles/creating-a-pull-request/) on github.\n6. Code review and merge\n7. Changes will be published to NPM within next version.\n\nThanks all the [contributors](https://github.com/Keyang/node-csvtojson/graphs/contributors)\n\n## Backers\n\nThank you to all our backers! [[Become a backer](https://opencollective.com/csvtojson#backer)]\n\n[![OpenCollective](https://opencollective.com/csvtojson/backers.svg?width=890)](https://opencollective.com/csvtojson#backer)\n\n## Sponsors\n\nThank you to all our sponsors! (please ask your company to also support this open source project by [becoming a sponsor](https://opencollective.com/csvtojson#sponsor))\n\n## Paypal \n\n[![donate](https://www.paypalobjects.com/en_US/i/btn/btn_donate_SM.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=DUBQLRPJADJFQ)\n\n# Browser Usage\n\nTo use `csvtojson` in browser is quite simple. There are two ways:\n\n**1. Embed script directly into script tag**\n\nThere is a pre-built script located in `browser/csvtojson.min.js`. Simply include that file in a `script` tag in `index.html` page:\n\n```html\n<script src=\"node_modules/csvtojson/browser/csvtojson.min.js\"></script>\n<!-- or use cdn -->\n<script src=\"https://cdn.rawgit.com/Keyang/node-csvtojson/d41f44aa/browser/csvtojson.min.js\"></script>\n```\nthen use a global `csv` function\n```html \n<script>\ncsv({\n\toutput: \"csv\"\n})\n.fromString(\"a,b,c\\n1,2,3\")\n.then(function(result){\n\n})\n</script>\n```\n\n\n\n**2. Use webpack or browserify**\n\nIf a module packager is preferred, just simply `require(\"csvtojson\")`:\n\n```js\nvar csv=require(\"csvtojson\");\n\n// or with import\nimport * as csv from \"csvtojson\";\n\n//then use csv as normal\n```\n",
  "readmeFilename": "readme.md",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/Keyang/node-csvtojson.git"
  },
  "scripts": {
    "build": "rm -Rf ./v2 && tsc && npm run build:browser && npm run build:browser:window",
    "build:browser": "webpack --config ./webpack.config.js",
    "build:browser:window": "webpack --config ./webpack.config.js --output-library-target=window --output-library=csv --output-filename=csvtojson.min.js",
    "coverage": "nyc --reporter html  mocha -r ts-node/register src/**/*.test.ts ./test/*.ts -R spec",
    "coveralls": "cat ./coverage/lcov.info | ./node_modules/.bin/coveralls",
    "dev": "tsc -w",
    "test": "rm -Rf .ts-node && TS_NODE_CACHE_DIRECTORY=.ts-node mocha -r ts-node/register src/**/*.test.ts ./test/*.ts -R spec",
    "test-all": "mocha  ./test -R spec && CSV_WORKER=3 mocha ./test -R spec ",
    "test:all:debug": "mocha debug ./testNew -R spec",
    "test:debug": "mocha debug -r ts-node/register src/**/*.test.ts ./test/*.ts -R spec",
    "test:function": "mocha -r ts-node/register test/**/*.ts",
    "test:unit": "mocha -r ts-node/register src/**/*.ts",
    "travis": "nyc --reporter lcov mocha -r ts-node/register src/**/*.test.ts ./test/*.ts -R spec"
  },
  "version": "2.0.10"
}
